{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae906ae",
   "metadata": {},
   "source": [
    "# KG-Hub: Getting Started (from scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2255d9f4",
   "metadata": {},
   "source": [
    "This notebook serves as a walkthrough for creating a KG-Hub project, building a new graph, and using the graph for machine learning. Some familiarity with the command line, GitHub, and Python will be helpful. This notebook also assumes you're running in a Linux environment, but it should be informative even if you're on Windows or some other fancy operating system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8292d",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [KG-Hub basics](#KG-Hub-basics)\n",
    "- [Planning and setup](#Planning-and-setup)\n",
    "- [Walking through the KG project](#Walking-through-the-KG-project)\n",
    "- [Setting up your new KG project](#Setting-up-your-new-KG-project)\n",
    "- [KGX format basics and the KGX config files](#KGX-format-basics-and-the-KGX-config-files)\n",
    "  - [The KGX format](#The-KGX-format)\n",
    "  - [KGX config files](#KGX-config-files)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61270fba",
   "metadata": {},
   "source": [
    "## KG-Hub basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dbf0e1",
   "metadata": {},
   "source": [
    "The purpose of Knowledge Graph Hub (KG-Hub) is to provide a platform for building knowledge graphs (KGs) by adopting a set of guidelines and design principles. The goal of KG-Hub is to serve as a collective resource to simplify the process of generating biological and biomedical KGs and thus reducing the barrier for entry to new participants.\n",
    "\n",
    "Each independent effort for building a KG is considered a KG-Hub project.\n",
    "\n",
    "Projects include a code repository and a storage location for each set of graph products. Repositories are generally on GitHub and storage is available on https://kg-hub.berkeleybop.io/.\n",
    "\n",
    "For example, the following are all KG-Hub project repositories and storage locations:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656d54e1",
   "metadata": {},
   "source": [
    "| **Name**    | **Repository**                                     | **Graphs**                                 |\n",
    "|-------------|----------------------------------------------------|--------------------------------------------|\n",
    "| KG-COVID-19 | https://github.com/Knowledge-Graph-Hub/kg-covid-19 | https://kg-hub.berkeleybop.io/kg-covid-19/ |\n",
    "| KG-IDG      | https://github.com/Knowledge-Graph-Hub/kg-idg      | https://kg-hub.berkeleybop.io/kg-idg/      |\n",
    "| KG-OBO      | https://github.com/Knowledge-Graph-Hub/kg-obo      | https://kg-hub.berkeleybop.io/kg-obo/      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e47017",
   "metadata": {},
   "source": [
    "\n",
    "Each project *should*:\n",
    "* live in its own GitHub repository within the [Knowledge-Graph-Hub](https://github.com/Knowledge-Graph-Hub/) organization.\n",
    "* have enough code and/or configurations for Extract, Transform, and Load (ETL) to yield a reproducible product.\n",
    "* model data using the [Biolink Model](https://biolink.github.io/biolink-model/), where possible.\n",
    "* make use of ontologies from the [OBO Foundry](http://www.obofoundry.org/), where possible.\n",
    "* be responsible for the veracity of the datasets that they ingest \n",
    "* be responsible for keeping track of evidence and provenance for assertions in their KG.\n",
    "* provide their KG for download, following [semantic versioning guidelines](https://semver.org/).\n",
    "* provide their KG in the [KGX interchange format](https://github.com/biolink/kgx/blob/master/specification/kgx-format.md) in addition to their format of choice (e.g., n-triples).\n",
    "\n",
    "We also *highly recommend* including the following in the repository: \n",
    "* a README describing the intended purpose of the KG and its contributors\n",
    "* a License (as its own LICENSE file) \n",
    "* Contributing guidelines\n",
    "* a Code of Conduct\n",
    "* statements emphasizing how the KG and KG-Hub are open to the community for contributions as well as consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f316c89d",
   "metadata": {},
   "source": [
    "## Planning and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40629ab9",
   "metadata": {},
   "source": [
    "You likely already found the KG-Hub project template repository - that's where this notebook is.\n",
    "If you found this someplace else, the template repository is https://github.com/Knowledge-Graph-Hub/kg-dtm-template.\n",
    "\n",
    "First, create a name for your project repository. In KG-Hub, most projects include **KG** somewhere, e.g., \"KG-Squid\" or \"KG-Mimivirus-Proteomics\".\n",
    "\n",
    "Make a new repository for your project, based on the template, in one of the following two ways:\n",
    "* [Follow the browser-based directions here.](https://docs.github.com/en/repositories/creating-and-managing-repositories/creating-a-repository-from-a-template)\n",
    "* Use the GitHub command line interface. This may be a preferable option if you're using a Windows command line and don't want to use a browser interface. Follow the [install instructions here](https://cli.github.com/manual/installation) as needed, then run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c344976",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ~/ \n",
    "!gh repo create kg-project-name --public --clone --template https://github.com/Knowledge-Graph-Hub/kg-dtm-template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b288796f",
   "metadata": {},
   "source": [
    "Next, select a name for your project. It should resemble your repository name, though any dashes will need to be changed to underscores.\n",
    "\n",
    "Change the values below to your repository name so they may be used later in the walkthrough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00bc73cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_repo_name = \"kg-placeholder-name\"\n",
    "kg_project_name = \"kg_placeholder_name\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db72e359",
   "metadata": {},
   "source": [
    "Define some additional details so they may be used later as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9698510",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = '' # A short description of the project\n",
    "long_description = '' # A slightly less short description of the project\n",
    "gh_name = '' # Your GitHub user name, assuming that you created the project repository in your own account.\n",
    "author_name = '' # Your name\n",
    "author_email = '' # Your email address"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45350acb",
   "metadata": {},
   "source": [
    "## Walking through the KG project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e25f2ea",
   "metadata": {},
   "source": [
    "Each KG project in KG-Hub is generally structured like this (with some omissions for clarity):\n",
    "```\n",
    "ðŸ“¦kg-project-name\n",
    " â”£ ðŸ“‚kg_project_name\n",
    " â”ƒ â”£ ðŸ“‚merge_utils\n",
    " â”ƒ â”ƒ â”— ðŸ“œmerge_kg.py - this produces the final, merged KG\n",
    " â”ƒ â”£ ðŸ“‚transform_utils - data source-specific transformation functions\n",
    " â”ƒ â”ƒ â”£ ðŸ“‚transform_one\n",
    " â”ƒ â”ƒ â”ƒ â”— ðŸ“œtransform_one.py\n",
    " â”ƒ â”ƒ â”£ ðŸ“‚transform_two\n",
    " â”ƒ â”ƒ â”ƒ â”— ðŸ“œtransform_two.py\n",
    " â”ƒ â”ƒ â”— ðŸ“œtransform.py - sets defaults for transform outputs\n",
    " â”ƒ â”£ ðŸ“‚utils - utilities and helper functions\n",
    " â”ƒ â”ƒ â”£ ðŸ“œdownload_utils.py\n",
    " â”ƒ â”ƒ â”£ ðŸ“œrobot_utils.py - utilities for working with the ROBOT tool\n",
    " â”ƒ â”ƒ â”— ðŸ“œtransform_utils.py\n",
    " â”ƒ â”£ ðŸ“œdownload.py \n",
    " â”ƒ â”— ðŸ“œtransform.py - sets up the individual transformations\n",
    " â”£ ðŸ“‚tests\n",
    " â”ƒ â”£ ðŸ“‚resources\n",
    " â”ƒ â”ƒ â”£ files required to run the tests\n",
    " â”ƒ â”£ various tests\n",
    " â”£ ðŸ“œLICENSE.txt\n",
    " â”£ ðŸ“œREADME.md - modify as needed\n",
    " â”£ ðŸ“œdownload.yaml - the download configuration file\n",
    " â”£ ðŸ“œmerge.yaml - the merge configuration file\n",
    " â”£ ðŸ“œrequirements.txt - empty by default, but add any new requirements here\n",
    " â”£ ðŸ“œrun.py - the main interface for downloading, transforming, and merging\n",
    " â”— ðŸ“œsetup.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a62dd5b",
   "metadata": {},
   "source": [
    "The general process of *defining* how to assemble a KG looks like this:\n",
    "1. Add data sources to `download.yaml`.\n",
    "2. Add a new transform to `transform.py` and in the `transform_utils` directory to handle the new data source. If the data source is already a set of KGX tsv node and edgelists, then it may only require a 'passthrough' tranform (i.e., files aren't modified but may be validated and moved). \n",
    "3. Modify `merge.yaml` to include the new sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fea6ea0",
   "metadata": {},
   "source": [
    "The general process of *assembling* the KG looks like this. Even if you haven't changed much in the new project yet, these commands will still retrieve several files, transform them, and merge them into a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03e33772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:03<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "!python run.py download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2842d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run.py transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacd7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run.py merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a06d5b",
   "metadata": {},
   "source": [
    "## Setting up your new KG project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3f7738",
   "metadata": {},
   "source": [
    "Before going any further, open the project in your favorite development environment. You will need to replace all instances of `project_name` with your project's name.\n",
    "\n",
    "You can also run the following script, assuming you've specified `kg_project_name` above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53440565",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$kg_project_name\"\n",
    "mv project_name/ $1\n",
    "find . -name \"*.py\" | xargs -n 1 sed -i -e \"s|project_name|$1|g\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7097a205",
   "metadata": {},
   "source": [
    "Next, update the `setup.py` file with some details about your project. You should only need to modify the first several lines of the `setup` block, as these define project metadata. Don't modify the value for `version` as that is defined elsewhere (specifically, in `project_name/__version__.py`). You may also need to change the value for `license` if you're using a license other than BSD-3. \n",
    "\n",
    "If you've defined metadata values in the \"Planning and setup\" section above, you may run the following, then copy and paste the result into your `setup.py` immediately under `setup(`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72537b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    name='kg_placeholder_name,\n",
      "    version=__version__,\n",
      "    description='',\n",
      "    long_description='',\n",
      "    url='https://github.com/Knowledge-Graph-Hub/kg-placeholder-name',\n",
      "    author='',\n",
      "    author_email='',\n",
      "    python_requires='>=3.7',\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( \n",
    "f\"\"\"\n",
    "    name='{kg_project_name},\n",
    "    version=__version__,\n",
    "    description='{description}',\n",
    "    long_description='{long_description}',\n",
    "    url='https://github.com/Knowledge-Graph-Hub/{kg_repo_name}',\n",
    "    author='{author_name}',\n",
    "    author_email='{author_email}',\n",
    "    python_requires='>=3.7',\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264bc04e",
   "metadata": {},
   "source": [
    "Now it's all yours! Feel free to update the README, too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5adb6c",
   "metadata": {},
   "source": [
    "## KGX format basics and the KGX config files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2518f4c4",
   "metadata": {},
   "source": [
    "Two more steps remain before the KG is ready to be built: setting up the KGX configuration files (specifially, `download.yaml` and `merge.yaml`). You've likely noticed that the three primary stages in this pipeline are to download, transform, and merge. These two configuration files handle the first and last stages, respectively, but transforms are source-specific and each requires its own process. \n",
    "\n",
    "Our goal is to get all data in the same format - KGX tab-separated values - and adhering to the same data model. The next section will discuss the [Biolink Model](https://biolink.github.io/biolink-model/), but there isn't anything preventing you from reading about it now. In short, we need as much consistency as possible before combining sources into a single KG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6abc190",
   "metadata": {},
   "source": [
    "### The KGX format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4762d5af",
   "metadata": {},
   "source": [
    "[You can find an exhaustive specification for the KGX data format here.](https://github.com/biolink/kgx/blob/master/specification/kgx-format.md)\n",
    "\n",
    "If you're already familiar with RDF, triples, and the idea of a [graph data model](https://www.w3.org/TR/2004/REC-rdf-concepts-20040210/#section-data-model) then this will all appear quite simple. If not, just consider nodes to be things and edges to be the relationships between those things. For example, a node may be a farmer and an edge may be a specific connection to something else which may or may not be the same type of thing, e.g., \"Farmer Alphonse *grows* lentils\".\n",
    "\n",
    "Here are the key points about KGX:\n",
    "* Each graph consists of one node file and one edge file.\n",
    "* Both files are tab-delimited and have a single header line each.\n",
    "* Both files contain one record per line - one node or one edge.\n",
    "\n",
    "A node file generally looks something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4f24bb",
   "metadata": {},
   "source": [
    "```\n",
    "id      category        name    description\n",
    "ENSEMBL:ENSG00000143933 biolink:Gene|biolink:NamedThing CALM2   calmodulin 2\n",
    "ENSEMBL:ENSG00000131089 biolink:Gene|biolink:NamedThing ARHGEF9 Cdc42 guanine nucleotide exchange factor 9\n",
    "ENSEMBL:ENSG00000147889 biolink:Gene|biolink:NamedThing CDKN2A  cyclin dependent kinase inhibitor 2A\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d314e",
   "metadata": {},
   "source": [
    "Note that each value in the `id` column is a [CURIE](https://en.wikipedia.org/wiki/CURIE). It contains a prefix denoting the data source (in this case, ENSEMBL) and, after the colon, an identifier. Each node shown here also has two categories, with the | character separating items in each list. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9442a559",
   "metadata": {},
   "source": [
    "An edge file generally looks something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c0ac03",
   "metadata": {},
   "source": [
    "```\n",
    "id      subject predicate       object\n",
    "urn:uuid:e99e9dd6-0b4f-416e-8c81-061b4a61711c   ENSEMBL:ENSP00000000233 biolink:interacts_with  ENSEMBL:ENSP0000027\n",
    "2298\n",
    "urn:uuid:a819d828-3df7-4384-8612-38a17e521320   ENSEMBL:ENSP00000000233 biolink:interacts_with  ENSEMBL:ENSP0000041\n",
    "8915\n",
    "urn:uuid:b412961f-8939-488a-bd37-6ae3bc7237b9   ENSEMBL:ENSP00000000233 biolink:interacts_with  ENSEMBL:ENSP0000035\n",
    "6737\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d316e",
   "metadata": {},
   "source": [
    "Here, each `id` is actually a [Uniform Resource Name](https://en.wikipedia.org/wiki/Uniform_Resource_Name) - this is for consistency because the KG may contain a mix of relationships from other sources *and* newly-created connections. The crucial aspect is the set of *subject*, *predicate*, and *object*, or \"*S* has relationship *P* with *O*\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe50f4ec",
   "metadata": {},
   "source": [
    "### KGX config files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b826277",
   "metadata": {},
   "source": [
    "The KGX configuration files usually remain in the root of each project. Run this to see the download config, `download.yaml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32ae5a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# This file is a list of things to be downloaded using the command:\r\n",
      "#   run.py download\r\n",
      "\r\n",
      "# To add a new item to be download, add a block like this - must have 'url',\r\n",
      "# 'local_name' is optional, use to avoid name collisions\r\n",
      "\r\n",
      "#  #\r\n",
      "#  # Description of source\r\n",
      "#  #\r\n",
      "#  -\r\n",
      "#    # brief comment about file, and optionally a local_name:\r\n",
      "#    url: http://curefordisease.org/some_data.txt\r\n",
      "#    local_name: some_data_more_chars_prevent_name_collision.pdf\r\n",
      "#\r\n",
      "#  For downloading from S3 buckets, see here for information about what URL to use:\r\n",
      "#  https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html#access-bucket-intro\r\n",
      "#  Amazon S3 virtual hosted style URLs follow the format shown below:\r\n",
      "#  https://bucket-name.s3.Region.amazonaws.com/key_name\r\n",
      "#\r\n",
      "---\r\n",
      "\r\n",
      "#\r\n",
      "# **** ROBOT ****\r\n",
      "#\r\n",
      "-\r\n",
      "  url: https://github.com/ontodev/robot/releases/download/v1.8.3/robot.jar\r\n",
      "  local_name: robot.jar\r\n",
      "-\r\n",
      "  url: https://raw.githubusercontent.com/ontodev/robot/master/bin/robot \r\n",
      "  local_name: robot\r\n",
      "\r\n",
      "# **** Ontology files ****\r\n",
      "#\r\n",
      "# ENVO\r\n",
      "#\r\n",
      "-\r\n",
      "  url: http://purl.obolibrary.org/obo/envo.json\r\n",
      "  local_name: envo.json\r\n",
      "#\r\n",
      "# CHEBI\r\n",
      "#\r\n",
      "-\r\n",
      "  url: http://purl.obolibrary.org/obo/chebi.owl.gz\r\n",
      "  local_name: chebi.owl.gz\r\n",
      "\r\n",
      "# **** Data sources ****\r\n",
      "#\r\n",
      "# Reactome \r\n",
      "# pre-transformed CHEBI to Pathway relationships\r\n",
      "#\r\n",
      "-\r\n",
      "  url: https://reactome.org/download/current/ChEBI2Reactome_PE_Pathway.txt\r\n",
      "  local_name: ChEBI2Reactome_PE_Pathway.txt\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head download.yaml --lines=60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa48b56d",
   "metadata": {},
   "source": [
    "By default, this file instructs KGX to download 5 separate files:\n",
    "* Two files for [ROBOT](http://robot.obolibrary.org/), the Java tool used for ontology processing\n",
    "* The [ENVO ontology](https://obofoundry.org/ontology/envo.html) in JSON format\n",
    "* The [CHEBI ontology](https://obofoundry.org/ontology/chebi.html), in OWL format, and in a GZ compressed file\n",
    "* A set of mappings between CHEBI and pathways in the [Reactome knowledge base](https://reactome.org/), as a tab-delimited txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5400a28",
   "metadata": {},
   "source": [
    "The downloads are all stored in the `data/raw` directory.\n",
    "\n",
    "The actual download process is handled by a separate package, [kghub-downloader](https://github.com/monarch-initiative/kghub-downloader), so consult the documentation for that package to see the full extent of options you can use with `download.yaml`. It isn't limited to downloading single files from HTTP URLs: there's functionality for FTP and for retrieving the results of Elasticsearch queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6325c710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\r\n",
      "configuration:\r\n",
      "  output_directory: data/merged\r\n",
      "  checkpoint: false\r\n",
      "\r\n",
      "merged_graph:\r\n",
      "  name: project_name graph\r\n",
      "  source:\r\n",
      "    chebi:\r\n",
      "      name: \"CHEBI\"\r\n",
      "      input:\r\n",
      "        format: tsv\r\n",
      "        filename:\r\n",
      "          - data/transformed/ontologies/chebi_nodes.tsv\r\n",
      "          - data/transformed/ontologies/chebi_edges.tsv\r\n",
      "    envo:\r\n",
      "      name: \"ENVO\"\r\n",
      "      input:\r\n",
      "        format: tsv\r\n",
      "        filename:\r\n",
      "          - data/transformed/ontologies/envo_nodes.tsv\r\n",
      "          - data/transformed/ontologies/envo_edges.tsv\r\n",
      "    chebi_to_reactome:\r\n",
      "      name: \"CHEBI to Reactome Pathways\"\r\n",
      "      input:\r\n",
      "        format: tsv\r\n",
      "        filename:\r\n",
      "          - data/transformed/reactome/chebi2reactome_nodes.tsv\r\n",
      "          - data/transformed/reactome/chebi2reactome_edges.tsv\r\n",
      "  operations:\r\n",
      "    - name: kgx.graph_operations.summarize_graph.generate_graph_stats\r\n",
      "      args:\r\n",
      "        graph_name: project_name graph\r\n",
      "        filename: merged_graph_stats.yaml\r\n",
      "        node_facet_properties:\r\n",
      "          - provided_by\r\n",
      "        edge_facet_properties:\r\n",
      "          - provided_by\r\n",
      "          - source\r\n",
      "  destination:\r\n",
      "    merged-kg-tsv:\r\n",
      "      format: tsv\r\n",
      "      compression: tar.gz\r\n",
      "      filename: merged-kg\r\n",
      "    merged-kg-nt:\r\n",
      "      format: nt\r\n",
      "      compression: gz\r\n",
      "      filename: project_name.nt.gz"
     ]
    }
   ],
   "source": [
    "!head merge.yaml --lines=60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855ee551",
   "metadata": {},
   "source": [
    "As the name implies, `merge.yaml` instructs KGX to merge specific transformed data into one or more merged output graphs. The transforms place their output in `data/merged`, so that directory is specified at the top. If `checkpoint` is set to True, then each input will be converted and saved to a TSV before merging, but this isn't necessary here. We have three `source`s: the ENVO ontology, the CHEBI ontology, and the CHEBI to Reactome pathway mappings, each in nice, convenient KGX TSV format. The `operations` block defines additional processes to perform in the course of the merge. Here, a statistics file describing the merged graph's projects is generated. Finally, the `destination` block allows us to define the format(s) of the merged graph. The default file tells KGX to produce a tar.gz compressed set of KGX TSVs *and* a gz-compressed n-triple format file. \n",
    "\n",
    "Give it a try, if you haven't done so already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d686f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading files:   0%|                                  | 0/5 [00:00<?, ?it/s]\r",
      "Downloading files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 23912.79it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python run.py download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "744fd4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing data/raw/chebi.owl.gz\n",
      "[KGX][cli_utils.py][    transform_source] INFO: Processing source 'chebi.json'\n",
      "Parsing data/raw/envo.json\n",
      "[KGX][cli_utils.py][    transform_source] INFO: Processing source 'envo.json'\n",
      "Parsing data/raw/ChEBI2Reactome_PE_Pathway.txt\n",
      "Transforming using source in project_name/transform_utils/reactome/chebi2reactome.yaml\n",
      "WARNING:koza.model.config.source_config:Could not load dataset description from metadata file\n"
     ]
    }
   ],
   "source": [
    "!python run.py transform # This may take a few minutes. Take a break - you deserve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d15574ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KGX][cli_utils.py][               merge] INFO: Spawning process for 'chebi'\n",
      "[KGX][cli_utils.py][               merge] INFO: Spawning process for 'envo'\n",
      "[KGX][cli_utils.py][               merge] INFO: Spawning process for 'chebi_to_reactome'\n",
      "[KGX][cli_utils.py][        parse_source] INFO: Processing source 'chebi'\n",
      "[KGX][cli_utils.py][        parse_source] INFO: Processing source 'envo'\n",
      "[KGX][cli_utils.py][        parse_source] INFO: Processing source 'chebi_to_reactome'\n",
      "[KGX][graph_merge.py][       add_all_nodes] INFO: Adding 6773 nodes from envo to chebi\n",
      "[KGX][graph_merge.py][        merge_graphs] INFO: Number of nodes merged between chebi and envo: 924\n",
      "[KGX][graph_merge.py][       add_all_edges] INFO: Adding 10370 edges from <kgx.graph.nx_graph.NxGraph object at 0x7fc5616d00d0> to <kgx.graph.nx_graph.NxGraph object at 0x7fc593c84040>\n",
      "[KGX][graph_merge.py][        merge_graphs] INFO: Number of edges merged between chebi and envo: 1329\n",
      "[KGX][graph_merge.py][       add_all_nodes] INFO: Adding 15717 nodes from chebi_to_reactome to chebi\n",
      "[KGX][graph_merge.py][        merge_graphs] INFO: Number of nodes merged between chebi and chebi_to_reactome: 2324\n",
      "[KGX][graph_merge.py][       add_all_edges] INFO: Adding 92569 edges from <kgx.graph.nx_graph.NxGraph object at 0x7fc57eb005e0> to <kgx.graph.nx_graph.NxGraph object at 0x7fc593c84040>\n",
      "[KGX][graph_merge.py][        merge_graphs] INFO: Number of edges merged between chebi and chebi_to_reactome: 0\n",
      "[KGX][cli_utils.py][               merge] INFO: Merged graph has 196791 nodes and 420049 edges\n",
      "[KGX][cli_utils.py][               merge] INFO: Writing merged graph to merged-kg-tsv\n",
      "[KGX][cli_utils.py][               merge] INFO: Writing merged graph to merged-kg-nt\n"
     ]
    }
   ],
   "source": [
    "!python run.py merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27787984",
   "metadata": {},
   "source": [
    "The merged graph will be in `data/merged`, as per the merge configuration.\n",
    "\n",
    "Let's take a quick look at `merged_graph_stats.yaml` to get an idea of what the merged graph contains. The log output of the merge will tell us how many nodes and edges the graph contains, but so will the graph stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1666cf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  total_edges: 420049\r\n",
      "  total_nodes: 196791\r\n"
     ]
    }
   ],
   "source": [
    "!grep total merged_graph_stats.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11298c36",
   "metadata": {},
   "source": [
    "Take a look at the list of values under `predicates` in the stats file for the list of all predicates, or look under `node_stats` to find the count of all nodes by category.\n",
    "\n",
    "The important point: **now you have a KG!** \n",
    "\n",
    "Presumably your interests extend beyond chemicals and pathways, though! In the following sections, you'll see how to customize your KG-Hub project for your own needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ef92b",
   "metadata": {},
   "source": [
    "## Biolink basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ff61f",
   "metadata": {},
   "source": [
    "Are you working with biological or biomedical data?\n",
    "\n",
    "No? OK, skip to the next section.\n",
    "\n",
    "Otherwise, you'll need to know at least a bit about the Biolink Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20c5b11",
   "metadata": {},
   "source": [
    "## How to write transforms for new sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16634958",
   "metadata": {},
   "source": [
    "### Writing transforms with Koza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607b681c",
   "metadata": {},
   "source": [
    "### Retrieving source graphs from KG-Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ff5f8b",
   "metadata": {},
   "source": [
    "## How and where to store results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7f12c0",
   "metadata": {},
   "source": [
    "### Jenkins builds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c02fa2a",
   "metadata": {},
   "source": [
    "## Loading graphs with GraPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5be114",
   "metadata": {},
   "source": [
    "## Embeddings and basic ML approaches w/ NEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a841d4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
