{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae906ae",
   "metadata": {
    "id": "cae906ae"
   },
   "source": [
    "# KG-Hub: Advanced Knowledge Graph Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2255d9f4",
   "metadata": {
    "id": "2255d9f4"
   },
   "source": [
    "This notebook serves as a practical guide to advanced KG-Hub features and resources. A brief review of the Getting Started tutorial notebook is not a strict prerequisite but may be helpful.  \n",
    "\n",
    "This notebook also assumes you are in a Linux environment, but Google Colab is an option as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2cc3a0",
   "metadata": {},
   "source": [
    "Here's an example question for our use case: which foods may impact DNA repair pathways? It's a broad question with many possible answers, or no answers at all. A KG may hold some clues. We don't want to be entirely reliant on existing data, however: starting with sets of chemicals, foods, and biological pathways, we can perform link prediction to predict additional connections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f316c89d",
   "metadata": {
    "id": "f316c89d"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40629ab9",
   "metadata": {
    "id": "40629ab9"
   },
   "source": [
    "First, we'll install the requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c344976",
   "metadata": {
    "id": "4c344976"
   },
   "outputs": [],
   "source": [
    "!pip install kgx\n",
    "!pip install kghub-downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b5175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uhYo2aVBaWe4",
   "metadata": {
    "id": "uhYo2aVBaWe4"
   },
   "source": [
    "Now we need to set up two things for KGX to work properly:\n",
    "* A download config file\n",
    "* A merge config file\n",
    "\n",
    "In practice, we may need to write a new transform for each new source, but all of the sources we'll use here are conveniently already available as KGX node and edge files on KG-Hub.\n",
    "\n",
    "We'll download five sources. Two are ontologies available through the KG-OBO project on KG-Hub: FOODON, a food ontology, and CHEBI, a chemical ontology. The other sources are sets of preprocessed [Reactome](https://reactome.org) pathways, connections between those pathways, and mappings between those pathways and chemicals. They're all defined in a dictionary below, with the name of each source as its key and a list of one or more source URLs as its value. We've also defined a set of local filenames, as we know what the compressed ontology files should contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dp81ZNcvb5Qn",
   "metadata": {
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1654291963120,
     "user": {
      "displayName": "Harry Caufield",
      "userId": "03176428528134146285"
     },
     "user_tz": 240
    },
    "id": "Dp81ZNcvb5Qn"
   },
   "outputs": [],
   "source": [
    "data_dir = \"./\" # Just the current directory, though in practice it would be something like data/raw/\n",
    "sources = {\"foodon\":[\"https://kg-hub.berkeleybop.io/kg-obo/foodon/2022-02-01/foodon_kgx_tsv.tar.gz\"],\n",
    "           \"chebi\":[\"https://kg-hub.berkeleybop.io/kg-obo/chebi/210/chebi_kgx_tsv.tar.gz\"],\n",
    "           \"chebi2reactome\":[\"https://kg-hub.berkeleybop.io/kg-idg/20220601/transformed/reactome/chebi2reactome_edges.tsv\",\n",
    "                             \"https://kg-hub.berkeleybop.io/kg-idg/20220601/transformed/reactome/chebi2reactome_nodes.tsv\"],\n",
    "           \"reactome_pathways\":[\"https://kg-hub.berkeleybop.io/kg-idg/20220601/transformed/reactome/reactomepathways_nodes.tsv\"],\n",
    "           \"reactome_relations\":[\"https://kg-hub.berkeleybop.io/kg-idg/20220601/transformed/reactome/reactomepathwaysrelation_edges.tsv\"]}\n",
    "local_filepaths = {\"foodon\":[\"foodon_kgx_tsv_edges.tsv\",\n",
    "                            \"foodon_kgx_tsv_nodes.tsv\"],\n",
    "           \"chebi\":[\"chebi_kgx_tsv_edges.tsv\",\n",
    "                    \"chebi_kgx_tsv_nodes.tsv\"],\n",
    "           \"chebi2reactome\":[\"chebi2reactome_edges.tsv\",\n",
    "                             \"chebi2reactome_nodes.tsv\"],\n",
    "           \"reactome_pathways\":[\"reactomepathways_nodes.tsv\"],\n",
    "           \"reactome_relations\":[\"reactomepathwaysrelation_edges.tsv\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jpdRBj8afOrE",
   "metadata": {
    "id": "jpdRBj8afOrE"
   },
   "source": [
    "There is an example of a KGX download config file [here](https://github.com/Knowledge-Graph-Hub/kg-dtm-template/blob/master/download.yaml), but it's easy to assemble from scratch with something like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pynXk66VfaOt",
   "metadata": {
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1654292390036,
     "user": {
      "displayName": "Harry Caufield",
      "userId": "03176428528134146285"
     },
     "user_tz": 240
    },
    "id": "pynXk66VfaOt"
   },
   "outputs": [],
   "source": [
    "source_data = []\n",
    "for source in sources:\n",
    "  for url in sources[source]:\n",
    "    local_name = url.rpartition('/')[-1]\n",
    "    source_data.append({\"url\":url,\n",
    "                        \"local_name\":local_name})\n",
    "\n",
    "with open(\"download.yaml\", \"w\") as dl_config:\n",
    "  yaml.dump(source_data, dl_config, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H_UK6orMgwuc",
   "metadata": {
    "id": "H_UK6orMgwuc"
   },
   "source": [
    "Now we may use the config file with the `kghub-downloader` to download all sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7L1P6k8tg3a4",
   "metadata": {
    "id": "7L1P6k8tg3a4"
   },
   "outputs": [],
   "source": [
    "!downloader download.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bf36cf",
   "metadata": {},
   "source": [
    "Decompress the compressed sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c89c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat *.tar.gz | tar zxvf - -i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f7b89",
   "metadata": {},
   "source": [
    "Next step: set up a merge config file. Our sources are already in the expected KGX graph format, so no transformation is necessary.\n",
    "\n",
    "See the [example merge config](https://github.com/Knowledge-Graph-Hub/kg-dtm-template/blob/master/merge.yaml) in this repository for further inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c68f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data = {\"configuration\":{\"output_directory\":data_dir,\n",
    "                              \"checkpoint\":\"false\"\n",
    "                              },\n",
    "              \"merged_graph\":{\"name\":\"tutorial_graph\",\n",
    "                              \"source\":{},\n",
    "                              \"operations\":[{\"name\": \"kgx.graph_operations.summarize_graph.generate_graph_stats\",\n",
    "                                        \"args\":{\"graph_name\":\"tutorial_graph\",\n",
    "                                        \"filename\":\"merged_graph_stats.yaml\"\n",
    "                                                }\n",
    "                                                }\n",
    "                                                ],\n",
    "                                \"destination\":{\"merged-kg-tsv\":{\"format\":\"tsv\",\n",
    "                                              \"filename\": \"merged-kg\"}\n",
    "                                                },            \n",
    "                                }\n",
    "                }\n",
    "\n",
    "for source in local_filepaths:\n",
    "  merge_data[\"merged_graph\"][\"source\"][source] = {\"name\":source,\n",
    "                                                  \"input\":{\"format\":\"tsv\",\n",
    "                                                          \"filename\":local_filepaths[source]}\n",
    "                                                  }\n",
    "\n",
    "with open(\"merge.yaml\", \"w\") as merge_config:\n",
    "  yaml.dump(merge_data, merge_config, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wWbNYTkRZ1Qz",
   "metadata": {
    "id": "wWbNYTkRZ1Qz"
   },
   "source": [
    "## KG Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d280092",
   "metadata": {},
   "source": [
    "The data files are all here and the configuration files are ready. We may now use `kgx` to assemble a single set of nodes and edges from them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aeee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kgx.cli.cli_utils import merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_graph = merge(\"merge.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68d92e7",
   "metadata": {},
   "source": [
    "If everything went as expected, the merged KG will be in `merged-kg_edges.tsv` and `merged-kg_nodes.tsv`. There will also be a `merged_graph_stats.yaml` detailing the new graph contents. Let's take a quick look at the stats file first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2324362",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"merged_graph_stats.yaml\") as yaml_file:\n",
    "    config = yaml.load(yaml_file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080cc2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of all edges in the graph\n",
    "print(config[\"edge_stats\"][\"total_edges\"])\n",
    "\n",
    "# Count of all nodes in the graph\n",
    "print(config[\"node_stats\"][\"total_nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What kind of nodes are in the graph?\n",
    "for category in config[\"node_stats\"][\"node_categories\"]:\n",
    "    print(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee332cb",
   "metadata": {},
   "source": [
    "Nodes in ontologies and data sources are assigned appropriate Biolink Model categories whenever possible. Those assigned `NamedThing` may still belong to a more detailed category, but assigning such a category may be challenging.\n",
    "\n",
    "Now let's take a look at the graph contents to begin examining how they may answer our questions.\n",
    "\n",
    "Let's get a set of all relations between food entries in FOODON and chemical entries in CHEBI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3587415",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep FOODON merged-kg_edges.tsv | grep CHEBI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb0f894",
   "metadata": {},
   "source": [
    "The \"subject, predicate, and object\" of each relation are found in the second, third, and fourth columns, respectively.\n",
    "I'll save you some trouble: every relation like `CHEBI:XXXXX    biolink:subclass_of FOODON:03412972` is just saying \"this chemical is a [food additive](https://www.ebi.ac.uk/ols/ontologies/foodon/terms?iri=http%3A%2F%2Fpurl.obolibrary.org%2Fobo%2FFOODON_03412972)\". There are several different *types* of relations in this set, however. We can get a quick idea about those types by looking at the `merged_graph_stats.yaml` KGX has prepared for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9983b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -n '/count_by_predicates/,/count_by_spo/p' merged_graph_stats.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b73ee5",
   "metadata": {},
   "source": [
    "We can see, for example, that there are >93 thousand \"participates_in\" relations. Let's see what the participants in these graph edges are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0cdb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -A 1 \"participates_in\" merged_graph_stats.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e7cd69",
   "metadata": {},
   "source": [
    "So these are our connections between chemicals and pathways. The same counts appear multiple times because each node may have more than one category (e.g., a ChemicalEntity is also a NamedThing).\n",
    "\n",
    "Continue to the next section for some examples of how to learn more about the new graph with the `grape` tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906f0ff",
   "metadata": {},
   "source": [
    "## Loading Graphs with `grape`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4862d",
   "metadata": {},
   "source": [
    "The `grape` library includes a substantial array of tools for working with graph data, generating reports and plots about graph contents, and preparing graph representations. We'll start by loading the graph from the previous section, then we'll get more details about its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install grape -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape import Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a3fc0e",
   "metadata": {},
   "source": [
    "Once the next block completes, it will output a long text report about the graph's properties and a variety of its \"topological oddities\". These don't mean anything is intrinsically *wrong* with the graph - rather, they are features of the data we have used to construct the graph. In some cases, for example, a CHEBI entry may be present within our imported data despite being deleted from the dataset and therefore obsolete, so it will be among the singleton nodes. These oddities *may* have an impact on the value of the graph embeddings we'll assemble in the next section and they *may* highlight areas where our data is structured in ways we may not expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph.from_csv(\n",
    "  directed=False, # This graph is, in fact, directed, but we'll treat it as undirected.\n",
    "  node_path='merged-kg_nodes.tsv',\n",
    "  edge_path='merged-kg_edges.tsv',\n",
    "  verbose=True,\n",
    "  nodes_column='id',\n",
    "  node_list_node_types_column='category',\n",
    "  default_node_type='biolink:NamedThing',\n",
    "  sources_column='subject',\n",
    "  destinations_column='object',\n",
    "  edge_list_edge_types_column='predicate',\n",
    "  name=\"A Nice KG\"\n",
    ")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4942957e",
   "metadata": {},
   "source": [
    "Now let's try to find all edges connecting nodes to a DNA repair pathway. The human DNA repair pathway as an ID of **R-HSA-73894** in Reactome, so in our graph it will have an identifier of **REACT:R-HSA-73894**. We can run the following to find all related edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step = g.get_neighbour_node_names_from_node_name(node_name=\"REACT:R-HSA-73894\")\n",
    "one_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca4285d",
   "metadata": {},
   "source": [
    "So this pathway only has other Reactome pathways as neighbors. That's fine - we can check for neighbors of those neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab9658",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_step = []\n",
    "for neighbor in one_step:\n",
    "    for result in g.get_neighbour_node_names_from_node_name(node_name=neighbor):\n",
    "        two_step.append(result)\n",
    "two_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771f9f12",
   "metadata": {},
   "source": [
    "Now things are getting interesting. Several of these nodes are CHEBI entries. These aren't drugs or environmental contaiminants, though: they're participants in the pathways, like CHEBI:16991 - that's just [DNA](https://www.ebi.ac.uk/ols/ontologies/chebi/terms?iri=http%3A%2F%2Fpurl.obolibrary.org%2Fobo%2FCHEBI_16991).\n",
    "\n",
    "We can see the whole path, in terms of the names of nodes in that path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3093fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.get_shortest_path_node_names_from_node_names(src_node_name=\"REACT:R-HSA-73894\", dst_node_name=\"CHEBI:456216\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c74c5a7",
   "metadata": {},
   "source": [
    "Using the same strategy, we can see if there are other paths of interest.\n",
    "\n",
    "Let's get a set of all FOODON entries and see if any of them have paths back to the DNA Repair pathway node. This will take a short while. We're also most interested in the _shortest_ paths, so we'll sort the paths by length and look at the shortest ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ca375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_nodes = []\n",
    "for result in g.get_node_names():\n",
    "    if result.startswith(\"FOODON\"):\n",
    "        food_nodes.append(result)\n",
    "\n",
    "print(f\"Found {len(food_nodes)} nodes from FOODON.\")\n",
    "\n",
    "food_paths = []\n",
    "for node in food_nodes:\n",
    "    try:\n",
    "        path = g.get_shortest_path_node_names_from_node_names(src_node_name=\"REACT:R-HSA-73894\", dst_node_name=node)\n",
    "        food_paths.append(path)\n",
    "    except ValueError:\n",
    "        print(f\"Couldn't find a path to the target from {node}.\")\n",
    "\n",
    "food_paths.sort(key=len)\n",
    "print(food_paths[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf747600",
   "metadata": {},
   "source": [
    "You can expect to find a few paths of length 5, at least. I'll spoil one of them:\n",
    "\n",
    "`['REACT:R-HSA-73894', 'REACT:R-HSA-73942', 'REACT:R-HSA-73943', 'CHEBI:16526', 'FOODON:03301011']`\n",
    "is a path from the DNA Repair pathway to the DNA Damage Reversal pathway to the \"Reversal of alkylation damage by DNA dioxygenases\" pathway which involves carbon dioxide (CHEBI:16526) as a component, as do carbonated beverages (FOODON:03301011). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ngMKIcWZ41K",
   "metadata": {
    "id": "8ngMKIcWZ41K"
   },
   "source": [
    "## Graph Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0fa230",
   "metadata": {},
   "source": [
    "The `grape` library is particularly efficient at preparing graph embeddings. \n",
    "Let's see a list of its available node embedding methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4731a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape import get_available_models_for_node_embedding\n",
    "get_available_models_for_node_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d6bfda",
   "metadata": {},
   "source": [
    "Let's use Ensmallen's implementation of a method named [HOPE](https://www.kdd.org/kdd2016/papers/files/rfp0184-ouA.pdf). For the sake of simplicity, we'll specify the metric as 'Adjacency' below. We'll also set `enable_cache` to true so the embeddings get saved locally (in the current working directory, under `/embedding/HOPE/Ensmallen/[name of the graph]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53de444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape.embedders import HOPEEnsmallen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db341a6",
   "metadata": {},
   "source": [
    "Remove disconnected nodes first, as they won't contribute much to our embeddings and may cause errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f15067",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = g.remove_disconnected_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HOPEEnsmallen(metric=\"Adjacency\",enable_cache=True)\n",
    "embedding = model.fit_transform(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f96da",
   "metadata": {},
   "source": [
    "Now let's see what those embeddings look like. They won't be too informative just yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.get_node_embedding_from_index(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ccaad",
   "metadata": {},
   "source": [
    "Now we'll create some plots. This may take a minute or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d59803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape import GraphVisualizer\n",
    "visualizer = GraphVisualizer(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87553354",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.fit_and_plot_all(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd6b54",
   "metadata": {},
   "source": [
    "These plots primarily serve to show how the graph contents may be separated based on the newly created embeddings. Ideally, we'd like there to be a clear feature distinguishing existing vs non-existing edges, or it will be difficult to predict which new edges may be likely to exist. Different embeddings and metrics are likely to correlate with potentially useful features, but there is no guarantee that any one feature will be sufficient for consistently predicting new edges.\n",
    "\n",
    "We can pass an embedding method by name, too - try the plot specified below and compare with the results above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c129d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = GraphVisualizer(g)\n",
    "visualizer.fit_and_plot_all(\"DeepWalk CBOW\",iterations=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ZjgrmtXZ77C",
   "metadata": {
    "id": "3ZjgrmtXZ77C"
   },
   "source": [
    "## Edge Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228e19f",
   "metadata": {},
   "source": [
    "We may finally try to predict some new edges between foods and pathways. As we saw above, there are no paths directly between only these two types of nodes. Instead, we can attempt to find new potential relationships between all nodes in the graph.\n",
    "\n",
    "At this point we'll just need to work with the largest fully connected component of the graph, as our methods won't work if all our nodes aren't connected to each other in some way. Let's see how many components are in the graph right now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.get_number_of_connected_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77414099",
   "metadata": {},
   "source": [
    "The displayed triple tells us the total number of components, the size of the smallest component in nodes, and the size of the largest component in nodes, respectively. Most importantly, there's more than one component in there. Let's trim it down to just the component containing our pathway of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_g = g.remove_components(node_names=['REACT:R-HSA-73894'])\n",
    "trim_g.get_number_of_connected_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478aaed4",
   "metadata": {},
   "source": [
    "That's better - we should have just one component now. We have a few options regarding next steps:\n",
    "*  We can use the node embeddings to train a model and apply the model to generate predicted edges. This will rely upon the topology of the graph. In practice, NEAT will run this entire pipeline, from graph loading to edge prediction, based on a single config file (see the Machine Learning on Knowledge Graphs tutorial notebook for an example). We'll skip that here as we've already done some of the work.\n",
    "* We can get node features based on their text with a BERT model.\n",
    "* We can use a node feature such as its category. Our graph doesn't have too many different sources and we haven't specified detailed categories, so this may not be very informative here.\n",
    "* We can use edge features.\n",
    "\n",
    "First, let's see some of the edge prediction methods we can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9568ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape.edge_prediction import edge_prediction_evaluation\n",
    "from grape import get_available_models_for_edge_prediction\n",
    "get_available_models_for_edge_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369eb21e",
   "metadata": {},
   "source": [
    "### Perceptron and Edge Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce34b0cd",
   "metadata": {},
   "source": [
    "The next step will evaluate how well Ensmallen's Perceptron model implementation works on edge prediction. Note that this doesn't include any embedding-derived features. Run with the `smoke_test` parameter set to True first to verify everything is working correctly - this will train the models for just one epoch - and then try again with that parameter disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a644c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embiggen.edge_prediction.edge_prediction_ensmallen.perceptron import PerceptronEdgePrediction\n",
    "my_model1 = PerceptronEdgePrediction(edge_features='JaccardCoefficient')\n",
    "my_model2 = PerceptronEdgePrediction(edge_features='AdamicAdar')\n",
    "my_model3 = PerceptronEdgePrediction(edge_features='Degree')\n",
    "holdouts = edge_prediction_evaluation(\n",
    "            holdouts_kwargs=dict(train_size=0.8),\n",
    "            models=[my_model1, my_model2, my_model3],\n",
    "            evaluation_schema=\"Connected Monte Carlo\",\n",
    "            graphs=trim_g,\n",
    "            number_of_holdouts=1,\n",
    "            enable_cache=True,\n",
    "            precompute_constant_automatic_stocastic_features=True,\n",
    "            smoke_test=True, # Set to False to run a full training across these models! This will take longer, of course.\n",
    "            verbose=True,\n",
    "            )\n",
    "holdouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1943364",
   "metadata": {},
   "source": [
    "If you ran this with the `smoke_test` parameter on, you likely got poor results, such as an f1 score of zero. Not surprising as this doesn't spend much time training the model. Even with extensive training, however, there's no guarantee that this method will capture the right blend of features for good edge prediction.\n",
    "\n",
    "Run the next block to yield predicted edges. This may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031a6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model1._fit(trim_g)\n",
    "my_model1._predict_proba(trim_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc62d1",
   "metadata": {},
   "source": [
    "### Text Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d2c23",
   "metadata": {},
   "source": [
    "Let's see if the names and descriptions of the nodes in our graph contain features useful for edge prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape.datasets import get_okapi_tfidf_weighted_textual_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974bbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = get_okapi_tfidf_weighted_textual_embedding('merged-kg_nodes.tsv',\n",
    "                                                       separator = \"\\t\",\n",
    "                                                       header = True,\n",
    "                                                      columns=[\"name\",\"description\"],\n",
    "                                                      verbose = True)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1120f433",
   "metadata": {},
   "source": [
    "We convert the embeddings to a dataframe so they can be mapped to the subset of nodes in our trimmed graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c333f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df = pd.DataFrame(embedding, index=g.get_node_names())\n",
    "subgraph_bert_df = bert_df.loc[trim_g.get_node_names()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41358a89",
   "metadata": {},
   "source": [
    "Now let's plot those BERT embeddings to see what we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccfe40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = GraphVisualizer(trim_g)\n",
    "visualizer.fit_and_plot_all(subgraph_bert_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc810dbf",
   "metadata": {},
   "source": [
    "The results are not terribly useful. There isn't a clear distinction between existing and non-existing edges. Let's try something else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d10d8f",
   "metadata": {},
   "source": [
    "### GCN and Node Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd3f085",
   "metadata": {},
   "source": [
    "Finally, let's try a graph convolutional network model with embeddings as node features. As above, the configuration provided here will do a test run, so disable `smoke_test` when you're ready to proceed with a more extensive training.\n",
    "\n",
    "This model uses Tensorflow, so verify it is installed on your system first, or run this on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b8c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embiggen.edge_prediction.edge_prediction_tensorflow.kipf_gcn import KipfGCNEdgePrediction\n",
    "gcn_model = KipfGCNEdgePrediction()\n",
    "\n",
    "holdouts = edge_prediction_evaluation(\n",
    "            holdouts_kwargs=dict(train_size=0.8),\n",
    "            models=[gcn_model],\n",
    "            evaluation_schema=\"Connected Monte Carlo\",\n",
    "            node_features=HOPEEnsmallen(metric=\"Adjacency\",enable_cache=True),\n",
    "            graphs=trim_g,\n",
    "            number_of_holdouts=1,\n",
    "            enable_cache=True,\n",
    "            precompute_constant_automatic_stocastic_features=True,\n",
    "            smoke_test=True, # Set to False to run a full training! This will take longer, of course.\n",
    "            verbose=True,\n",
    "            )\n",
    "holdouts"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Advanced Knowledge Graph Assembly",
   "provenance": []
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
